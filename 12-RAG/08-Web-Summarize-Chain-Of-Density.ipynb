{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Density: https://arxiv.org/pdf/2309.04269.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\"https://teddylee777.github.io/data-science/optuna/\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "\n",
    "# Get this prompt template\n",
    "prompt = hub.pull(\"lawwu/chain_of_density\")\n",
    "\n",
    "# The chat model output is a JSON list of dicts, with SimpleJsonOutputParser\n",
    "# we can convert it o a dict, and it suppors streaming.\n",
    "json_parser = SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"ARTICLE\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n",
    "    | json_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Missing_Entities': 'Optuna',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization library for machine learning. Optuna provides a simple and efficient way to search for the best hyperparameters for a given model. It offers various methods for suggesting hyperparameters, such as categorical, integer, and float values. By using Optuna, you can optimize your machine learning models and improve their performance.'},\n",
       " {'Missing_Entities': 'trial.suggest_categorical',\n",
       "  'Denser_Summary': 'Optuna provides the trial.suggest_categorical() method for suggesting categorical hyperparameters. This method allows you to specify a name for the hyperparameter and a list of choices. Optuna will then suggest the best value from the given choices. By using trial.suggest_categorical(), you can easily optimize your machine learning models by finding the optimal categorical hyperparameters.'},\n",
       " {'Missing_Entities': 'trial.suggest_int',\n",
       "  'Denser_Summary': 'Another method provided by Optuna is trial.suggest_int() for suggesting integer hyperparameters. You can specify the name of the hyperparameter, the lower and upper bounds, and an optional step size. Optuna will suggest the best integer value within the specified range. By using trial.suggest_int(), you can optimize your machine learning models by finding the optimal integer hyperparameters.'},\n",
       " {'Missing_Entities': 'trial.suggest_float',\n",
       "  'Denser_Summary': 'Optuna also provides the trial.suggest_float() method for suggesting float hyperparameters. Similar to trial.suggest_int(), you can specify the name of the hyperparameter, the lower and upper bounds, and an optional step size. Optuna will suggest the best float value within the specified range. By using trial.suggest_float(), you can optimize your machine learning models by finding the optimal float hyperparameters.'},\n",
       " {'Missing_Entities': 'objective function',\n",
       "  'Denser_Summary': 'The objective function is a key component in using Optuna for hyperparameter optimization. It is the function that evaluates the performance of a given set of hyperparameters. By defining an objective function, you can use Optuna to search for the best hyperparameters that minimize or maximize the evaluation metric. The objective function takes the trial object, the model, the input data, the target data, and the evaluation metric as parameters. By optimizing the objective function, you can improve the performance of your machine learning models.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"\",\n",
      "        \"Denser_Summary\": \"이 기사는 데이터사이언스, 머신러닝, 인공지능에 대한 개념을 설명하고 있습니다. 이 분야들이 우리 생활에 어떻게 적용되고 있는지, 그리고 이 분야를 공부하고자 하는 사람들이 어떻게 시작해야 할지에 대한 조언을 제공합니다. 또한, 이 기술들이 어떻게 빠르게 발전하고 있는지에 대해서도 다루고 있습니다. 이러한 기술들의 기본적인 정의와 차이점, 그리고 이 분야에서 일하려면 어떤 준비가 필요한지에 대한 정보를 제공하고자 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"박정현 서울대 EPM 연구원; OpenAI의 대화형 GPT-3; 데이터사이언스가 가장 큰 범주\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원이 작성한 이 기사는 데이터사이언스, 머신러닝, 인공지능의 기본 개념과 차이점을 설명합니다. OpenAI의 대화형 GPT-3 같은 최신 프로젝트 예시를 들며, 데이터사이언스가 현재 가장 큰 범주로 설명됩니다. 이 분야의 실용적 적용 사례와 공부 방향에 대한 조언도 포함되어, 기술 발전과 함께 이 분야의 중요성을 강조합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"'인공지능 국가전략' 발표; 지도학습과 비지도 학습; 튜링테스트\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 차이점을 설명하며, '인공지능 국가전략' 발표와 OpenAI의 GPT-3 프로젝트를 언급합니다. 데이터사이언스가 가장 넓은 범주로, 지도학습과 비지도 학습을 포함하는 머신러닝, 튜링테스트를 기반으로 한 인공지능의 개념을 소개합니다. 이 분야의 실생활 적용과 학습 방향에 대한 조언도 제공됩니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"약한 인공지능과 강한 인공지능; k-means 알고리즘; 퍼듀 대학의 윌리엄 클리블랜드 교수\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 차이점을 설명하며, '인공지능 국가전략' 발표와 OpenAI의 GPT-3를 언급합니다. 데이터사이언스가 가장 넓은 범주로, 지도학습, 비지도 학습, k-means 알고리즘을 포함합니다. 약한 인공지능과 강한 인공지능의 구분, 튜링테스트 기반 인공지능 정의, 퍼듀 대학의 윌리엄 클리블랜드 교수의 예측을 소개합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"이메일 스팸 필터링; 룰 기반 시스템; 머신러닝 기반 시스템\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 차이점을 설명하며, '인공지능 국가전략' 발표와 OpenAI의 GPT-3를 언급합니다. 데이터사이언스가 가장 넓은 범주로, 지도학습, 비지도 학습, k-means 알고리즘을 포함합니다. 약한 인공지능과 강한 인공지능의 구분, 튜링테스트 기반 인공지능 정의, 퍼듀 대학의 윌리엄 클리블랜드 교수의 예측을 소개합니다. 이메일 스팸 필터링의 룰 기반 시스템과 머신러닝 기반 시스템의 차이를 설명합니다.\"\n",
      "    }\n",
      "]\n",
      "```박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 차이점을 설명하며, '인공지능 국가전략' 발표와 OpenAI의 GPT-3를 언급합니다. 데이터사이언스가 가장 넓은 범주로, 지도학습, 비지도 학습, k-means 알고리즘을 포함합니다. 약한 인공지능과 강한 인공지능의 구분, 튜링테스트 기반 인공지능 정의, 퍼듀 대학의 윌리엄 클리블랜드 교수의 예측을 소개합니다. 이메일 스팸 필터링의 룰 기반 시스템과 머신러닝 기반 시스템의 차이를 설명합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import json\n",
    "\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.aitimes.com/news/articleView.html?idxno=131777\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "# Load the prompt\n",
    "# prompt = hub.pull(\"langchain-ai/chain-of-density:4f55305e\")\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 5 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (50 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the chain, including\n",
    "chain = (\n",
    "    prompt\n",
    "    | ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    )\n",
    "    | JsonOutputParser()\n",
    "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"ARTICLE\": content})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
